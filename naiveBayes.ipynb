{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # Data loading Function sets\n",
    "    - ## load train function\n",
    "    - ## load test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "directory = 'C:\\\\Users\\\\went1\\\\Desktop\\\\ml_practice'\n",
    "\n",
    "def loadTrainData():\n",
    "    trainImgPath = os.path.join(directory, 'train-images.idx3-ubyte')\n",
    "    trainLablePath = os.path.join(directory, 'train-labels.idx1-ubyte')\n",
    "    \n",
    "    with open(trainImgPath, 'rb') as trainImgRawData:\n",
    "        header = []\n",
    "        for i in range(4):\n",
    "            byte = trainImgRawData.read(4)\n",
    "            header.append(int.from_bytes(byte, byteorder=\"big\"))\n",
    "        magic, trainImgLength, rows, col = header\n",
    "        trainImages = np.fromfile(trainImgRawData, dtype=np.uint8).reshape(trainImgLength, 784)\n",
    "        \n",
    "    with open(trainLablePath, 'rb') as trainLableRawData:\n",
    "        header = []\n",
    "        for i in range(2):\n",
    "            byte = trainLableRawData.read(4)\n",
    "            header.append(int.from_bytes(byte, byteorder=\"big\"))\n",
    "        magic, trainLabelLength = header\n",
    "        trainLabels = np.fromfile(trainLableRawData, dtype=np.uint8)\n",
    "        \n",
    "    return trainImages, trainLabels ##train img is 60000*784 array.\n",
    "        \n",
    "def loadTestData():\n",
    "    testImgPath = os.path.join(directory, 't10k-images.idx3-ubyte')\n",
    "    testLablePath = os.path.join(directory, 't10k-labels.idx1-ubyte')\n",
    "    \n",
    "    with open(testImgPath, 'rb') as testImgRawData:\n",
    "        header = []\n",
    "        for i in range(4):\n",
    "            byte = testImgRawData.read(4)\n",
    "            header.append(int.from_bytes(byte, byteorder=\"big\"))\n",
    "        magic, testImgLength, rows, col = header\n",
    "        testImages = np.fromfile(testImgRawData, dtype=np.uint8).reshape(testImgLength, 784)\n",
    "        \n",
    "    with open(testLablePath, 'rb') as testLableRawData:\n",
    "        header = []\n",
    "        for i in range(2):\n",
    "            byte = testLableRawData.read(4)\n",
    "            header.append(int.from_bytes(byte, byteorder=\"big\"))\n",
    "        magic, testLabelLength = header\n",
    "        testLabels = np.fromfile(testLableRawData, dtype=np.uint8)\n",
    "        \n",
    "    return testImages, testLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # Naive Bayes function sets\n",
    "    * ## normalizing pixel value between 1 to 32.\n",
    "    * ## putting pixels into tally bins.(createBinstable)\n",
    "    * ## calculate likelihood\n",
    "    * ## calculate prior\n",
    "    * ## fit\n",
    "    * ## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class naiveBayes:\n",
    "    def __init__(self, toggle, smoothing):\n",
    "        self.toggle = toggle\n",
    "        self.smoothing = smoothing\n",
    "        \n",
    "    def normalizePixels(self, data):\n",
    "        for i in range(len(data)):\n",
    "            data[i] = np.floor(data[i]/8)\n",
    "\n",
    "    def createBinsAndCounts(self, X, y):\n",
    "        self.counts = np.empty(10)\n",
    "        self.bins = np.zeros([10, 32, 784])\n",
    "        self.bins += self.smoothing\n",
    "        for i in range(10):\n",
    "            imgs = X[y == i]\n",
    "            l = len(imgs)\n",
    "            self.counts[i] = l\n",
    "            for j in range(l):\n",
    "                for p in range(784):\n",
    "                    self.bins[i][imgs[j][p]][p] += 1\n",
    "   \n",
    "    def discreteModelTrain(self, X_train, y_train):\n",
    "        self.createBinsAndCounts(X_train, y_train)\n",
    "        ## Calculate likelihood.\n",
    "        for i in range(10):\n",
    "            for j in range(32):\n",
    "                    self.bins[i][j] = (self.bins[i][j]) / (self.counts[i]) ## bins will become likelihood.\n",
    "        ## Calculate prior.\n",
    "        self.priors = np.zeros(10)\n",
    "        for i in range(10):\n",
    "            self.priors[i] = self.counts[i] / 60000\n",
    "\n",
    "    def discreteModelPredict(self, X_test, y_test):\n",
    "        self.posteriorList = np.zeros([10000, 10])\n",
    "        error = 0\n",
    "        for i in range(10000):\n",
    "            for j in range(10):\n",
    "                for k in range(784):\n",
    "                      self.posteriorList[i][j] += np.log(self.bins[j][X_test[i][k]][k])\n",
    "            predict = np.argmax(self.posteriorList[i])\n",
    "            if predict != y_test[i]:\n",
    "                error += 1\n",
    "        self.errorRate = (error / 10000) * 100 # percentage format\n",
    "\n",
    "    def continuousModelTrain(self, X_train, y_train):\n",
    "        pixelValueSum = np.zeros([10, 784])\n",
    "        self.pixelValueMean = np.empty([10, 784]) ## means\n",
    "        self.pixelValueVar = np.empty([10, 784]) ## variances\n",
    "        self.priors = np.zeros(10)\n",
    "        ## This for loop generate every pixels mean\n",
    "        for i in range(10):\n",
    "            imgs = X_train[y_train == i]\n",
    "            l = len(imgs)\n",
    "            self.priors[i] = l / 60000\n",
    "            for j in range(l):\n",
    "                pixelValueSum[i] += imgs[j]\n",
    "            self.pixelValueMean[i] = pixelValueSum[i] / l\n",
    "\n",
    "        ## This for loop generate every pixels var\n",
    "        pixelValueSum = np.zeros([10, 784])\n",
    "        for i in range(10):\n",
    "            imgs = X_train[y_train == i]\n",
    "            l = len(imgs)\n",
    "            for j in range(l):\n",
    "                pixelValueSum[i] += np.power((imgs[j] - self.pixelValueMean[i]), 2)\n",
    "            self.pixelValueVar[i] = pixelValueSum[i] / l\n",
    "\n",
    "    def continuousModelPredict(self, X_test, y_test):\n",
    "        constant = 1 / np.sqrt(2 * np.pi)\n",
    "        self.posteriorList = np.zeros([10000, 10])\n",
    "        error = 0\n",
    "        for i in range(10000):\n",
    "            for j in range(10):\n",
    "                var = self.pixelValueVar[j] + self.smoothing\n",
    "                power = -((X_test[i] - self.pixelValueMean[j]) ** 2) / (2 * var)\n",
    "                prob = constant * (1 / np.sqrt(var)) * np.exp(power)\n",
    "                self.posteriorList[i][j] = np.sum(np.log(prob))        \n",
    "            predict = np.argmax(self.posteriorList[i])\n",
    "            if predict != y_test[i]:\n",
    "                error += 1\n",
    "        self.errorRate = (error / 10000) * 100 # percentage format\n",
    "    \n",
    "    def fit(self, X_train, y_train):        \n",
    "        if self.toggle == 0:\n",
    "            self.normalizePixels(X_train)\n",
    "            self.normalizePixels(X_test)\n",
    "            self.discreteModelTrain(X_train, y_train)\n",
    "        else:\n",
    "            self.continuousModelTrain(X_train, y_train)\n",
    "            \n",
    "    def predict(self, X_test, y_test):\n",
    "        if self.toggle == 0:\n",
    "            self.discreteModelPredict(X_test, y_test)\n",
    "            return self.posteriorList, self.errorRate\n",
    "        else:\n",
    "            self.continuousModelPredict(X_test, y_test)\n",
    "            return self.posteriorList, self.errorRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Machine Learning below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = loadTrainData()\n",
    "X_test, y_test = loadTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate for Gaussian MLE naiveBayes:  18.509999999999998 %\n",
      "Error Rate for discrete naiveBayes:  14.99 %\n"
     ]
    }
   ],
   "source": [
    "model_continuous = naiveBayes(toggle = 1, smoothing = 1000)\n",
    "model_continuous.fit(X_train, y_train)\n",
    "posteriorList, errorRate = model_continuous.predict(X_test, y_test)\n",
    "print('Error Rate for Gaussian MLE naiveBayes: ', errorRate, '%')\n",
    "model_discrete = naiveBayes(toggle = 0, smoothing = 0.1)\n",
    "model_discrete.fit(X_train, y_train)\n",
    "posteriorList, errorRate = model_discrete.predict(X_test, y_test)\n",
    "print('Error Rate for discrete naiveBayes: ', errorRate, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework2-2 online learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial beta distribution parameter a and b for online learning\n",
      "a:5\n",
      "b:5\n",
      "Line: 0\n",
      "Likelihood: 0.17971\n",
      "Prior: 1.0402539682539685e-06\n",
      "New posterior parameter: 13 17\n",
      "Line: 1\n",
      "Likelihood: 0.24385\n",
      "Prior: 4.85286153482938e-07\n",
      "New posterior parameter: 17 24\n",
      "Line: 2\n",
      "Likelihood: 0.25496\n",
      "Prior: 0.0001945864666413107\n",
      "New posterior parameter: 27 27\n",
      "Line: 3\n",
      "Likelihood: 0.19361\n",
      "Prior: 2.2754541004711918e-05\n",
      "New posterior parameter: 37 34\n",
      "Line: 4\n",
      "Likelihood: 0.21769\n",
      "Prior: 3.2683054275421163e-06\n",
      "New posterior parameter: 43 41\n",
      "Line: 5\n",
      "Likelihood: 0.23845\n",
      "Prior: 6.193403541368789e-05\n",
      "New posterior parameter: 51 45\n",
      "Line: 6\n",
      "Likelihood: 0.21154\n",
      "Prior: 1.8044924157034524e-05\n",
      "New posterior parameter: 59 51\n",
      "Line: 7\n",
      "Likelihood: 0.19787\n",
      "Prior: 2.1305116307404307e-06\n",
      "New posterior parameter: 66 60\n",
      "Line: 8\n",
      "Likelihood: 0.18213\n",
      "Prior: 6.193403541368789e-05\n",
      "New posterior parameter: 80 67\n",
      "Line: 9\n",
      "Likelihood: 0.22768\n",
      "Prior: 0.00013276110527092505\n",
      "New posterior parameter: 91 71\n",
      "Line: 10\n",
      "Likelihood: 0.24385\n",
      "Prior: 4.268765415778494e-05\n",
      "New posterior parameter: 98 75\n",
      "Line: 11\n",
      "Likelihood: 0.28163\n",
      "Prior: 6.207398005894252e-07\n",
      "New posterior parameter: 101 80\n",
      "Line: 12\n",
      "Likelihood: 0.3125\n",
      "Prior: 6.200396825396825e-06\n",
      "New posterior parameter: 104 83\n",
      "Line: 13\n",
      "Likelihood: 0.23061\n",
      "Prior: 0.00010755612943789086\n",
      "New posterior parameter: 114 87\n",
      "Line: 14\n",
      "Likelihood: 0.21431\n",
      "Prior: 6.193403541368789e-05\n",
      "New posterior parameter: 124 92\n",
      "Line: 15\n",
      "Likelihood: 0.28163\n",
      "Prior: 3.695724502442375e-05\n",
      "New posterior parameter: 129 95\n"
     ]
    }
   ],
   "source": [
    "binaryFilePath = os.path.join(directory, 'hw2_data.txt')\n",
    "\n",
    "with open(binaryFilePath) as f:\n",
    "    data = f.read().splitlines()\n",
    "\n",
    "print('Initial beta distribution parameter a and b for online learning')\n",
    "\n",
    "a = int(input('a:'))\n",
    "b = int(input('b:'))\n",
    "\n",
    "def factorial(n):\n",
    "    if n == 0: return 1 \n",
    "    return n * factorial(n-1)\n",
    "    \n",
    "def combination(N, m):\n",
    "    return factorial(N) / (factorial(m) * factorial(N-m))\n",
    "\n",
    "def gamma(n):\n",
    "    return factorial(n-1)\n",
    "\n",
    "def betaFunction(p):\n",
    "    return np.power(p, a-1) * np.power(p, b-1) * (gamma(a) * gamma(b) / gamma(a+b))\n",
    "\n",
    "def onlineLearning(data, a, b):\n",
    "    for i, val in enumerate(data):\n",
    "        print('Line:', i)\n",
    "        m = 0\n",
    "        N = len(val)\n",
    "        for bit in val:\n",
    "            if bit == '1':\n",
    "                m += 1\n",
    "        mleProb = m / N\n",
    "        likelihood = round(combination(N, m) * np.power(mleProb, m) * np.power((1 - mleProb), N-m), 5)\n",
    "        prior = betaFunction(mleProb)\n",
    "        a = a + m\n",
    "        b = b + N - m\n",
    "        print('Likelihood:', likelihood)\n",
    "        print('Prior:', prior)\n",
    "        print('New posterior parameter:', a, b)\n",
    "        \n",
    "onlineLearning(data, a, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
